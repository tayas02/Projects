{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44c06cdb7d7c41ca8d983b58e79f93a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_711f219f6b104be4add4f8cf141909aa",
              "IPY_MODEL_e635d7ee37a94609ba8a04c61756da9f",
              "IPY_MODEL_61849461d4ee427ba2b0cb37fb72c79e"
            ],
            "layout": "IPY_MODEL_20d1fbab76db4a6491e4dc08301a2b5c"
          }
        },
        "711f219f6b104be4add4f8cf141909aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7fe14453e854f41b3a7339c373679fa",
            "placeholder": "​",
            "style": "IPY_MODEL_990d2b1ad83e44bfb7ee19f96827e196",
            "value": "modules.json: 100%"
          }
        },
        "e635d7ee37a94609ba8a04c61756da9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed17fc8d87b44d08011c51d27cf2870",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8867280bf8d4c09a595592b1f3d761d",
            "value": 349
          }
        },
        "61849461d4ee427ba2b0cb37fb72c79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de269b9153445f88539eb79960e1b75",
            "placeholder": "​",
            "style": "IPY_MODEL_00cbc7a1a64349b58439fef93df7c725",
            "value": " 349/349 [00:00&lt;00:00, 11.6kB/s]"
          }
        },
        "20d1fbab76db4a6491e4dc08301a2b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fe14453e854f41b3a7339c373679fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990d2b1ad83e44bfb7ee19f96827e196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed17fc8d87b44d08011c51d27cf2870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8867280bf8d4c09a595592b1f3d761d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5de269b9153445f88539eb79960e1b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00cbc7a1a64349b58439fef93df7c725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83dd32d2aaf748afa5a029c58698edca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14ffb0b9c7de4ef28cdbb9241a7dbe7b",
              "IPY_MODEL_a2e3179be42e4be3923cec50c51ab9b3",
              "IPY_MODEL_e3b22035ed244b6fb5fa23a1dc2c4561"
            ],
            "layout": "IPY_MODEL_700db202f3174e79ad4bac5d07734da4"
          }
        },
        "14ffb0b9c7de4ef28cdbb9241a7dbe7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c1ac8cfa28429a8f6c5fabf2c769f9",
            "placeholder": "​",
            "style": "IPY_MODEL_31052b74b8924b0e9e7178542b3d1efe",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a2e3179be42e4be3923cec50c51ab9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3e88f6b12e4bfea1e014de86fd0314",
            "max": 201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63190d952eb94f599e75a1f94f9055b7",
            "value": 201
          }
        },
        "e3b22035ed244b6fb5fa23a1dc2c4561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7434496ebb94433924dfe254939bace",
            "placeholder": "​",
            "style": "IPY_MODEL_111ec78fe49c4c46b002e78ef66e7568",
            "value": " 201/201 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "700db202f3174e79ad4bac5d07734da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7c1ac8cfa28429a8f6c5fabf2c769f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31052b74b8924b0e9e7178542b3d1efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db3e88f6b12e4bfea1e014de86fd0314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63190d952eb94f599e75a1f94f9055b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7434496ebb94433924dfe254939bace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111ec78fe49c4c46b002e78ef66e7568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a39e32d58a8e43bc98f353c234d31ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23162f121f684039adeceaee53d46dc0",
              "IPY_MODEL_7d50e2eeff8a4735b80aea1e6f110d15",
              "IPY_MODEL_26d7b9ecbbd94c6a8fddc8354f2a79a4"
            ],
            "layout": "IPY_MODEL_62f854bfd25f4925ae517fcfc2ed70fb"
          }
        },
        "23162f121f684039adeceaee53d46dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b51d347eb94b05b67bd1cb4065f370",
            "placeholder": "​",
            "style": "IPY_MODEL_6245ce816efa41e4bac6206946b82af2",
            "value": "README.md: 100%"
          }
        },
        "7d50e2eeff8a4735b80aea1e6f110d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_357d755b132c4de298bc984b6f7c21b7",
            "max": 3040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1045d33ba664531bc2b0e83ab83cb88",
            "value": 3040
          }
        },
        "26d7b9ecbbd94c6a8fddc8354f2a79a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354096b98f1645dda6e59ff7fd85dc35",
            "placeholder": "​",
            "style": "IPY_MODEL_730a03f82d974bd797069bb26f6f89fc",
            "value": " 3.04k/3.04k [00:00&lt;00:00, 167kB/s]"
          }
        },
        "62f854bfd25f4925ae517fcfc2ed70fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b51d347eb94b05b67bd1cb4065f370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6245ce816efa41e4bac6206946b82af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "357d755b132c4de298bc984b6f7c21b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1045d33ba664531bc2b0e83ab83cb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "354096b98f1645dda6e59ff7fd85dc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730a03f82d974bd797069bb26f6f89fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05f8b89074ff485e9fc844582450fb50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ca7300494a48cabba47291d63f56a9",
              "IPY_MODEL_6ec2486fcc9d4552856063f2678b471d",
              "IPY_MODEL_4d5b86fc13ba4a2aafef981716e25e17"
            ],
            "layout": "IPY_MODEL_b16f26916a3344c1a84d2345bb299823"
          }
        },
        "63ca7300494a48cabba47291d63f56a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af76be11ad0d4fc6a0fc321ff376473f",
            "placeholder": "​",
            "style": "IPY_MODEL_d180ccb5a925472bb6abd12d0b8735a1",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "6ec2486fcc9d4552856063f2678b471d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e39967fd6b3496282af21e23e7742ed",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4387631ecbe349938ddbbfa76bded20f",
            "value": 53
          }
        },
        "4d5b86fc13ba4a2aafef981716e25e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812ff780f656415d8f36c6fe26a283d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f632fff26e5e4c0ebf2122079b26d698",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.47kB/s]"
          }
        },
        "b16f26916a3344c1a84d2345bb299823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af76be11ad0d4fc6a0fc321ff376473f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d180ccb5a925472bb6abd12d0b8735a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e39967fd6b3496282af21e23e7742ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4387631ecbe349938ddbbfa76bded20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812ff780f656415d8f36c6fe26a283d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f632fff26e5e4c0ebf2122079b26d698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e27c601d0ac24983a7eef061ad3f837d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12f27ebd625147d68cce64d0953b5979",
              "IPY_MODEL_1c337b6b26a34f91b3aa87dba102ba19",
              "IPY_MODEL_6346b1e78bae410bbfae0c8eb9b9c06e"
            ],
            "layout": "IPY_MODEL_dd3a4fb55daf4d779bf6629b6e40b8a9"
          }
        },
        "12f27ebd625147d68cce64d0953b5979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed55dc0814f4598b9dd5d8ccbe2fa67",
            "placeholder": "​",
            "style": "IPY_MODEL_e172c12cfe514446a1dbd4d044dca802",
            "value": "config.json: 100%"
          }
        },
        "1c337b6b26a34f91b3aa87dba102ba19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2cb35988aff46ff8790146206b7ccea",
            "max": 742,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9faf1fab5c7647b398fea2fb8773184b",
            "value": 742
          }
        },
        "6346b1e78bae410bbfae0c8eb9b9c06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e85bb054134d7b82425f064985fa49",
            "placeholder": "​",
            "style": "IPY_MODEL_5da4d727c03746c8b607704e062c0f15",
            "value": " 742/742 [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "dd3a4fb55daf4d779bf6629b6e40b8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed55dc0814f4598b9dd5d8ccbe2fa67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e172c12cfe514446a1dbd4d044dca802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2cb35988aff46ff8790146206b7ccea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9faf1fab5c7647b398fea2fb8773184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77e85bb054134d7b82425f064985fa49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da4d727c03746c8b607704e062c0f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9defa25562044727b7c0088be0b0177d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faae6906e0fc4dc0906f3e373df68b41",
              "IPY_MODEL_d3ebb4c56cf04ea98f83564c510dfc8a",
              "IPY_MODEL_e538e2e947a440bdac5d8e21fd56a794"
            ],
            "layout": "IPY_MODEL_26f6c8ff81b242dd85e65724a693041c"
          }
        },
        "faae6906e0fc4dc0906f3e373df68b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b303e7b1b249485580112adeb2cb9ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_55fb85d24a664922b74b33b6e532c8b3",
            "value": "model.safetensors: 100%"
          }
        },
        "d3ebb4c56cf04ea98f83564c510dfc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc84d6a8d2e74348af43edf6de092620",
            "max": 1340612432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d3ec0063429441fa28d0cf838be379f",
            "value": 1340612432
          }
        },
        "e538e2e947a440bdac5d8e21fd56a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070dba7aabed4acaba98e78400d2fc25",
            "placeholder": "​",
            "style": "IPY_MODEL_48124922495341fd845f8b974df988c3",
            "value": " 1.34G/1.34G [00:31&lt;00:00, 42.6MB/s]"
          }
        },
        "26f6c8ff81b242dd85e65724a693041c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b303e7b1b249485580112adeb2cb9ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55fb85d24a664922b74b33b6e532c8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc84d6a8d2e74348af43edf6de092620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3ec0063429441fa28d0cf838be379f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "070dba7aabed4acaba98e78400d2fc25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48124922495341fd845f8b974df988c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93d381e1502a4879ad13a101b3141d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d18dd8f0f2c443cc85bcce6ce230fc46",
              "IPY_MODEL_7a9c135181154d4aa7b6e1c78292de96",
              "IPY_MODEL_30a217a5927f41e1832a3c2397a4b92c"
            ],
            "layout": "IPY_MODEL_2c5c3316700a4eaeaef958257e4a642f"
          }
        },
        "d18dd8f0f2c443cc85bcce6ce230fc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70f8b1e52adf48bd9d05366445ffbea5",
            "placeholder": "​",
            "style": "IPY_MODEL_159879428607448c8654da5d88d59073",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7a9c135181154d4aa7b6e1c78292de96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0ac8176609d44efa489504265e199dd",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8248b46121814cb399b317e739f87cf1",
            "value": 1242
          }
        },
        "30a217a5927f41e1832a3c2397a4b92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59be8b827b2849789eb9adff116f55bf",
            "placeholder": "​",
            "style": "IPY_MODEL_76ecfd4a86454e9180c77efeb523756f",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 58.8kB/s]"
          }
        },
        "2c5c3316700a4eaeaef958257e4a642f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f8b1e52adf48bd9d05366445ffbea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159879428607448c8654da5d88d59073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0ac8176609d44efa489504265e199dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8248b46121814cb399b317e739f87cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59be8b827b2849789eb9adff116f55bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ecfd4a86454e9180c77efeb523756f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3edac17c2dc84caaa04d5cb5791b89be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94068840d9334df580db4e465937956e",
              "IPY_MODEL_10e71acebeda4dcd8b1ea87f00e23d4c",
              "IPY_MODEL_5cd6cc0eea0c417395cd4d2fb63bc097"
            ],
            "layout": "IPY_MODEL_fbd3650460a64d4eb57beb50b9f097c0"
          }
        },
        "94068840d9334df580db4e465937956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5f136aeaa44bb4b7268f903f349b82",
            "placeholder": "​",
            "style": "IPY_MODEL_42c77b5948bc4316b89f1f2a9b434fdc",
            "value": "vocab.txt: 100%"
          }
        },
        "10e71acebeda4dcd8b1ea87f00e23d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447cd39b2e564148aba36be7ecfcd591",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be84785054bf4694bcf16fc2f6c8fb74",
            "value": 231508
          }
        },
        "5cd6cc0eea0c417395cd4d2fb63bc097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571e93a964b849e5ac54ec17c4bd7d74",
            "placeholder": "​",
            "style": "IPY_MODEL_eb6bf2c454734e53bb39daede89cd1b8",
            "value": " 232k/232k [00:00&lt;00:00, 3.52MB/s]"
          }
        },
        "fbd3650460a64d4eb57beb50b9f097c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5f136aeaa44bb4b7268f903f349b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c77b5948bc4316b89f1f2a9b434fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "447cd39b2e564148aba36be7ecfcd591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be84785054bf4694bcf16fc2f6c8fb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "571e93a964b849e5ac54ec17c4bd7d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb6bf2c454734e53bb39daede89cd1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6014934148e8428b9cb16217c5950354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27789d83c88d4c1380db01e7ab92e967",
              "IPY_MODEL_7126384eda654e4e97e00ca5cf45e718",
              "IPY_MODEL_ac5d21ee2b0947fe80b47e86dc969cfa"
            ],
            "layout": "IPY_MODEL_c649e1dae4d24d3d8f6cffc31d682ba0"
          }
        },
        "27789d83c88d4c1380db01e7ab92e967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_094874c4f17642219bf6da58d884db58",
            "placeholder": "​",
            "style": "IPY_MODEL_69db95cd38ae4cf8acd24dcc8fd18a30",
            "value": "tokenizer.json: 100%"
          }
        },
        "7126384eda654e4e97e00ca5cf45e718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead938e7ae89481a9c7378ea20c3e780",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ac2b882f88a460c947bec057e942cfd",
            "value": 711396
          }
        },
        "ac5d21ee2b0947fe80b47e86dc969cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d716acb559240b29670a8aa513560e0",
            "placeholder": "​",
            "style": "IPY_MODEL_b59a1424d6a44dc4802f9d11ad11ba5d",
            "value": " 711k/711k [00:00&lt;00:00, 11.9MB/s]"
          }
        },
        "c649e1dae4d24d3d8f6cffc31d682ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094874c4f17642219bf6da58d884db58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69db95cd38ae4cf8acd24dcc8fd18a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ead938e7ae89481a9c7378ea20c3e780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac2b882f88a460c947bec057e942cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d716acb559240b29670a8aa513560e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59a1424d6a44dc4802f9d11ad11ba5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52347f3426d94fe9a2af8cfa667c2988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4faf13386a1940bc97041aaa17cf1104",
              "IPY_MODEL_5b2d781dbb2a4dc2ba1a96ad6acb5498",
              "IPY_MODEL_a82670e45c7d4d87b8b31fd4f28d5d33"
            ],
            "layout": "IPY_MODEL_fedca9da46314e5f9a0b2b77c4e25e53"
          }
        },
        "4faf13386a1940bc97041aaa17cf1104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3282406ca2e04500a7a3b79fd74b9ba1",
            "placeholder": "​",
            "style": "IPY_MODEL_39cab80b268c475985694644f554bfd8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5b2d781dbb2a4dc2ba1a96ad6acb5498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457ed023bc76410caa5fa0225c263afc",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c9cb8caad724736a9ef947059d1ecac",
            "value": 695
          }
        },
        "a82670e45c7d4d87b8b31fd4f28d5d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0895ce0bb94ceab1ab207fe0f96234",
            "placeholder": "​",
            "style": "IPY_MODEL_cd093eeff5fc4beda94ab11016dc52ff",
            "value": " 695/695 [00:00&lt;00:00, 40.2kB/s]"
          }
        },
        "fedca9da46314e5f9a0b2b77c4e25e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3282406ca2e04500a7a3b79fd74b9ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39cab80b268c475985694644f554bfd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "457ed023bc76410caa5fa0225c263afc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9cb8caad724736a9ef947059d1ecac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd0895ce0bb94ceab1ab207fe0f96234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd093eeff5fc4beda94ab11016dc52ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ec33f983b248d78042774225c409f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49ef4acaa765488fb53ef81a2881072f",
              "IPY_MODEL_ac51594bd1d94a529f787f80ee787048",
              "IPY_MODEL_4ab4b354af864e47aa068ee26a4a5191"
            ],
            "layout": "IPY_MODEL_0d9bf4bfc58d49aabf9a56e66f363f25"
          }
        },
        "49ef4acaa765488fb53ef81a2881072f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a615539a404563a191f32e83f2b97c",
            "placeholder": "​",
            "style": "IPY_MODEL_318149b571014a8e86e55d84d4b4f22f",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "ac51594bd1d94a529f787f80ee787048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9deede70e3b4fec8225366f0805fea5",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81038c403a0a49a4a66e3265b6bbe6bd",
            "value": 297
          }
        },
        "4ab4b354af864e47aa068ee26a4a5191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9887cf61be9447df8b16927ac1e05997",
            "placeholder": "​",
            "style": "IPY_MODEL_dfc976bd869e4dbd98cb726c46739bb8",
            "value": " 297/297 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "0d9bf4bfc58d49aabf9a56e66f363f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a615539a404563a191f32e83f2b97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318149b571014a8e86e55d84d4b4f22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9deede70e3b4fec8225366f0805fea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81038c403a0a49a4a66e3265b6bbe6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9887cf61be9447df8b16927ac1e05997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc976bd869e4dbd98cb726c46739bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xit_VOBjLrqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1549512-3ee5-4248-dfd3-c30ab4b2922c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m923.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -q pdfplumber sentence-transformers torch tqdm pyngrok streamlit datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from tqdm import tqdm\n",
        "import pdfplumber\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "model = SentenceTransformer(\"abhinand/MedEmbed-large-v0.1\")"
      ],
      "metadata": {
        "id": "whYE2DEMMGMW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534,
          "referenced_widgets": [
            "44c06cdb7d7c41ca8d983b58e79f93a3",
            "711f219f6b104be4add4f8cf141909aa",
            "e635d7ee37a94609ba8a04c61756da9f",
            "61849461d4ee427ba2b0cb37fb72c79e",
            "20d1fbab76db4a6491e4dc08301a2b5c",
            "d7fe14453e854f41b3a7339c373679fa",
            "990d2b1ad83e44bfb7ee19f96827e196",
            "8ed17fc8d87b44d08011c51d27cf2870",
            "a8867280bf8d4c09a595592b1f3d761d",
            "5de269b9153445f88539eb79960e1b75",
            "00cbc7a1a64349b58439fef93df7c725",
            "83dd32d2aaf748afa5a029c58698edca",
            "14ffb0b9c7de4ef28cdbb9241a7dbe7b",
            "a2e3179be42e4be3923cec50c51ab9b3",
            "e3b22035ed244b6fb5fa23a1dc2c4561",
            "700db202f3174e79ad4bac5d07734da4",
            "a7c1ac8cfa28429a8f6c5fabf2c769f9",
            "31052b74b8924b0e9e7178542b3d1efe",
            "db3e88f6b12e4bfea1e014de86fd0314",
            "63190d952eb94f599e75a1f94f9055b7",
            "d7434496ebb94433924dfe254939bace",
            "111ec78fe49c4c46b002e78ef66e7568",
            "a39e32d58a8e43bc98f353c234d31ac2",
            "23162f121f684039adeceaee53d46dc0",
            "7d50e2eeff8a4735b80aea1e6f110d15",
            "26d7b9ecbbd94c6a8fddc8354f2a79a4",
            "62f854bfd25f4925ae517fcfc2ed70fb",
            "f2b51d347eb94b05b67bd1cb4065f370",
            "6245ce816efa41e4bac6206946b82af2",
            "357d755b132c4de298bc984b6f7c21b7",
            "b1045d33ba664531bc2b0e83ab83cb88",
            "354096b98f1645dda6e59ff7fd85dc35",
            "730a03f82d974bd797069bb26f6f89fc",
            "05f8b89074ff485e9fc844582450fb50",
            "63ca7300494a48cabba47291d63f56a9",
            "6ec2486fcc9d4552856063f2678b471d",
            "4d5b86fc13ba4a2aafef981716e25e17",
            "b16f26916a3344c1a84d2345bb299823",
            "af76be11ad0d4fc6a0fc321ff376473f",
            "d180ccb5a925472bb6abd12d0b8735a1",
            "5e39967fd6b3496282af21e23e7742ed",
            "4387631ecbe349938ddbbfa76bded20f",
            "812ff780f656415d8f36c6fe26a283d5",
            "f632fff26e5e4c0ebf2122079b26d698",
            "e27c601d0ac24983a7eef061ad3f837d",
            "12f27ebd625147d68cce64d0953b5979",
            "1c337b6b26a34f91b3aa87dba102ba19",
            "6346b1e78bae410bbfae0c8eb9b9c06e",
            "dd3a4fb55daf4d779bf6629b6e40b8a9",
            "1ed55dc0814f4598b9dd5d8ccbe2fa67",
            "e172c12cfe514446a1dbd4d044dca802",
            "c2cb35988aff46ff8790146206b7ccea",
            "9faf1fab5c7647b398fea2fb8773184b",
            "77e85bb054134d7b82425f064985fa49",
            "5da4d727c03746c8b607704e062c0f15",
            "9defa25562044727b7c0088be0b0177d",
            "faae6906e0fc4dc0906f3e373df68b41",
            "d3ebb4c56cf04ea98f83564c510dfc8a",
            "e538e2e947a440bdac5d8e21fd56a794",
            "26f6c8ff81b242dd85e65724a693041c",
            "b303e7b1b249485580112adeb2cb9ee7",
            "55fb85d24a664922b74b33b6e532c8b3",
            "fc84d6a8d2e74348af43edf6de092620",
            "8d3ec0063429441fa28d0cf838be379f",
            "070dba7aabed4acaba98e78400d2fc25",
            "48124922495341fd845f8b974df988c3",
            "93d381e1502a4879ad13a101b3141d6c",
            "d18dd8f0f2c443cc85bcce6ce230fc46",
            "7a9c135181154d4aa7b6e1c78292de96",
            "30a217a5927f41e1832a3c2397a4b92c",
            "2c5c3316700a4eaeaef958257e4a642f",
            "70f8b1e52adf48bd9d05366445ffbea5",
            "159879428607448c8654da5d88d59073",
            "b0ac8176609d44efa489504265e199dd",
            "8248b46121814cb399b317e739f87cf1",
            "59be8b827b2849789eb9adff116f55bf",
            "76ecfd4a86454e9180c77efeb523756f",
            "3edac17c2dc84caaa04d5cb5791b89be",
            "94068840d9334df580db4e465937956e",
            "10e71acebeda4dcd8b1ea87f00e23d4c",
            "5cd6cc0eea0c417395cd4d2fb63bc097",
            "fbd3650460a64d4eb57beb50b9f097c0",
            "0c5f136aeaa44bb4b7268f903f349b82",
            "42c77b5948bc4316b89f1f2a9b434fdc",
            "447cd39b2e564148aba36be7ecfcd591",
            "be84785054bf4694bcf16fc2f6c8fb74",
            "571e93a964b849e5ac54ec17c4bd7d74",
            "eb6bf2c454734e53bb39daede89cd1b8",
            "6014934148e8428b9cb16217c5950354",
            "27789d83c88d4c1380db01e7ab92e967",
            "7126384eda654e4e97e00ca5cf45e718",
            "ac5d21ee2b0947fe80b47e86dc969cfa",
            "c649e1dae4d24d3d8f6cffc31d682ba0",
            "094874c4f17642219bf6da58d884db58",
            "69db95cd38ae4cf8acd24dcc8fd18a30",
            "ead938e7ae89481a9c7378ea20c3e780",
            "0ac2b882f88a460c947bec057e942cfd",
            "6d716acb559240b29670a8aa513560e0",
            "b59a1424d6a44dc4802f9d11ad11ba5d",
            "52347f3426d94fe9a2af8cfa667c2988",
            "4faf13386a1940bc97041aaa17cf1104",
            "5b2d781dbb2a4dc2ba1a96ad6acb5498",
            "a82670e45c7d4d87b8b31fd4f28d5d33",
            "fedca9da46314e5f9a0b2b77c4e25e53",
            "3282406ca2e04500a7a3b79fd74b9ba1",
            "39cab80b268c475985694644f554bfd8",
            "457ed023bc76410caa5fa0225c263afc",
            "9c9cb8caad724736a9ef947059d1ecac",
            "bd0895ce0bb94ceab1ab207fe0f96234",
            "cd093eeff5fc4beda94ab11016dc52ff",
            "44ec33f983b248d78042774225c409f0",
            "49ef4acaa765488fb53ef81a2881072f",
            "ac51594bd1d94a529f787f80ee787048",
            "4ab4b354af864e47aa068ee26a4a5191",
            "0d9bf4bfc58d49aabf9a56e66f363f25",
            "f2a615539a404563a191f32e83f2b97c",
            "318149b571014a8e86e55d84d4b4f22f",
            "d9deede70e3b4fec8225366f0805fea5",
            "81038c403a0a49a4a66e3265b6bbe6bd",
            "9887cf61be9447df8b16927ac1e05997",
            "dfc976bd869e4dbd98cb726c46739bb8"
          ]
        },
        "outputId": "9d34ec75-d360-4343-9a78-c6fb9f7e9c07"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44c06cdb7d7c41ca8d983b58e79f93a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83dd32d2aaf748afa5a029c58698edca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a39e32d58a8e43bc98f353c234d31ac2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05f8b89074ff485e9fc844582450fb50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e27c601d0ac24983a7eef061ad3f837d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9defa25562044727b7c0088be0b0177d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93d381e1502a4879ad13a101b3141d6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3edac17c2dc84caaa04d5cb5791b89be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6014934148e8428b9cb16217c5950354"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52347f3426d94fe9a2af8cfa667c2988"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44ec33f983b248d78042774225c409f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "login(token=os.environ['HF_TOKEN'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCIHPgtLV6Bn",
        "outputId": "784a5b45-4513-4a97-fb1c-7fb7a4ccaeb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss Function\n",
        "class MytryoshkaLoss(nn.Module):\n",
        "    def __init__(self, margin: float = 0.2):\n",
        "        super(MytryoshkaLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, query_embeddings, positive_embeddings, negative_embeddings):\n",
        "        positive_similarity = F.cosine_similarity(query_embeddings, positive_embeddings)\n",
        "        negative_similarity = F.cosine_similarity(query_embeddings, negative_embeddings)\n",
        "        loss = torch.relu(self.margin + negative_similarity - positive_similarity)\n",
        "        return loss.mean()\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(file_path):\n",
        "    try:\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# File Upload\n",
        "def upload_file():\n",
        "    uploaded = files.upload()\n",
        "    for file_name in uploaded.keys():\n",
        "        print(f\"Uploaded file: {file_name}\")\n",
        "    return list(uploaded.keys())[0]\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            print(f\"No relevant documents for query {idx}.\")\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Calculate Similarity Threshold\n",
        "def calculate_similarity_threshold(similarity_matrix, percentile=75):\n",
        "    all_similarities = similarity_matrix.flatten()\n",
        "    threshold = np.percentile(all_similarities, percentile)\n",
        "    print(f\"Calculated similarity threshold (percentile {percentile}): {threshold}\")\n",
        "    return threshold\n",
        "\n",
        "# Fine-Tune Model\n",
        "def fine_tune_model(query, candidates, model, top_k=5):\n",
        "    query_embeddings = model.encode([query], convert_to_tensor=True, convert_to_numpy=False)\n",
        "    candidate_embeddings = model.encode(candidates, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "    similarity_threshold = calculate_similarity_threshold(similarity_matrix)\n",
        "\n",
        "    ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "    print(\"Automatically Derived Ground Truth:\", ground_truth)\n",
        "\n",
        "    if not ground_truth[0]:\n",
        "        print(f\"No relevant candidates found for the query '{query}' under the current threshold.\")\n",
        "        ground_truth = [[i for i in range(len(candidates))]]\n",
        "\n",
        "    train_examples = []\n",
        "    for i, query in enumerate([query]):\n",
        "        positives = [candidates[idx] for idx in ground_truth[i]]\n",
        "        negatives = [candidates[idx] for idx in range(len(candidates)) if idx not in ground_truth[i]]\n",
        "        for pos in positives:\n",
        "            for neg in negatives:\n",
        "                train_examples.append(InputExample(texts=[query, pos, neg]))\n",
        "\n",
        "    if len(train_examples) == 0:\n",
        "        print(\"Warning: No training examples generated.\")\n",
        "        return\n",
        "\n",
        "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8, collate_fn=collate_fn)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "    loss_function = MytryoshkaLoss(margin=0.03)\n",
        "\n",
        "    model.train()\n",
        "    epochs = 1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}\")\n",
        "        epoch_loss = 0\n",
        "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
        "            query_emb, pos_emb, neg_emb = batch\n",
        "            loss = loss_function(query_emb, pos_emb, neg_emb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth, top_k=top_k)\n",
        "        print(f\"Epoch {epoch + 1} Validation Metrics:\")\n",
        "        print(f\"MRR: {mrr:.4f}\")\n",
        "        print(f\"NDCG: {ndcg:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    model.save(\"med_model_output\")\n",
        "    print(\"Model saved as 'med_model_output'.\")\n",
        "\n",
        "# Information Retrieval\n",
        "def information_retrieval(query, candidates, model):\n",
        "    query_embedding = model.encode([query], convert_to_tensor=True, convert_to_numpy=False)\n",
        "    candidate_embeddings = model.encode(candidates, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "    similarity_matrix = torch.mm(query_embedding, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_scores = similarity_matrix[0]\n",
        "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
        "    top_k = 3\n",
        "\n",
        "    top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "    return top_candidates\n",
        "\n",
        "# Collate Function\n",
        "def collate_fn(batch):\n",
        "    queries = [item.texts[0] for item in batch]\n",
        "    positives = [item.texts[1] for item in batch]\n",
        "    negatives = [item.texts[2] for item in batch]\n",
        "\n",
        "    query_emb = model.encode(queries, convert_to_tensor=True, convert_to_numpy=False)\n",
        "    pos_emb = model.encode(positives, convert_to_tensor=True, convert_to_numpy=False)\n",
        "    neg_emb = model.encode(negatives, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "    query_emb.requires_grad_()\n",
        "    pos_emb.requires_grad_()\n",
        "    neg_emb.requires_grad_()\n",
        "\n",
        "    return query_emb, pos_emb, neg_emb\n",
        "\n",
        "# Main Workflow\n",
        "file_path = upload_file()\n",
        "extracted_text = parse_pdf(file_path)\n",
        "\n",
        "if extracted_text:\n",
        "    candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"Enter your query: \")\n",
        "        model = SentenceTransformer('abhinand/MedEmbed-large-v0.1')\n",
        "        fine_tune_model(query, candidates, model)\n",
        "        top_candidates = information_retrieval(query, candidates, model)\n",
        "\n",
        "        print(\"Top 3 Relevant Content:\")\n",
        "        for idx, candidate in enumerate(top_candidates):\n",
        "            print(f\"Rank {idx + 1}: {candidate}\")\n",
        "\n",
        "        continue_query = input(\"Do you want to ask another query? (yes/no): \").strip().lower()\n",
        "        if continue_query != \"yes\":\n",
        "            print(\"Exiting the query loop.\")\n",
        "            break\n",
        "else:\n",
        "    print(\"Failed to extract text from the PDF.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "vX44h3MENRPR",
        "outputId": "1060b3aa-2d33-43fc-e182-6e9109aeeefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cb9466e2-6994-41e3-8607-9bf58456cd31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cb9466e2-6994-41e3-8607-9bf58456cd31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BP.pdf to BP (8).pdf\n",
            "Uploaded file: BP (8).pdf\n",
            "Enter your query: how hypertension occurs?\n",
            "Calculated similarity threshold (percentile 75): 0.7158874571323395\n",
            "Automatically Derived Ground Truth: [[2, 3]]\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:25<00:00, 12.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.0000\n",
            "Epoch 1 Validation Metrics:\n",
            "MRR: 1.0000\n",
            "NDCG: 1.0000\n",
            "Recall: 1.0000\n",
            "Model saved as 'med_model_output'.\n",
            "Top 3 Relevant Content:\n",
            "Rank 1: doctor’s visit, while orthostatic hypotension is a sudden drop in blood pressure when standing. Common causes of hypertension include obesity, smoking, excessive alcohol, high salt intake, lack of exercise, and genetics. For hypotension, causes include dehydration, heart problems, endocrine issues, blood vessel problems, and severe infections. Prevention of blood pressure issues includes lifestyle modifications such as a healthy diet rich in fruits, vegetables, and lean proteins, reducing sodium intake,\n",
            "Rank 2: blood pressure). Hypertension can be primary, with no clear cause but influenced by factors such as genetics, poor diet, obesity, and high salt intake, or secondary, caused by other conditions like kidney disease or certain medications. Hypotension occurs when blood pressure is too low, leading to symptoms such as dizziness or fainting. It can result from dehydration, blood loss, heart problems, or infections. White Coat Syndrome refers to elevated blood pressure readings due to anxiety during a\n",
            "Rank 3: Blood pressure refers to the force that circulating blood exerts against the walls of blood vessels, especially the arteries. The heart pumps blood into the arteries, generating pressure. Blood is carried through arteries, arterioles, capillaries, and then back to the heart through venules and veins. Systolic pressure is the highest pressure when the heart contracts, while diastolic pressure is the lowest pressure when the heart is at rest. Blood pressure is regulated by factors like cardiac output, blood volume,\n",
            "Do you want to ask another query? (yes/no): no\n",
            "Exiting the query loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pdfplumber sentence-transformers pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "696XKfZSWq0U",
        "outputId": "62e843ba-8870-424f-9a8a-95ed76c784a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.1 streamlit-1.40.2 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "\n",
        "# Custom Loss Function\n",
        "class MytryoshkaLoss(torch.nn.Module):\n",
        "    def __init__(self, margin: float = 0.2):\n",
        "        super(MytryoshkaLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, query_embeddings, positive_embeddings, negative_embeddings):\n",
        "        positive_similarity = F.cosine_similarity(query_embeddings, positive_embeddings)\n",
        "        negative_similarity = F.cosine_similarity(query_embeddings, negative_embeddings)\n",
        "        loss = torch.relu(self.margin + negative_similarity - positive_similarity)\n",
        "        return loss.mean()\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Fine-Tuning and IR\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            model = SentenceTransformer('abhinand/MedEmbed-large-v0.1')\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True, convert_to_numpy=False)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Display Derived Ground Truth\n",
        "            st.write(\"Automatically Derived Ground Truth:\")\n",
        "            st.write(ground_truth)\n",
        "\n",
        "            # Metrics Calculation\n",
        "            mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "            st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "            st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "            st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvEtMhVxcT5l",
        "outputId": "aab52142-4202-4d0a-866c-326134d86747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import SentenceTransformer, InputExample\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "\n",
        "# Custom Loss Function\n",
        "class MytryoshkaLoss(torch.nn.Module):\n",
        "    def __init__(self, margin: float = 0.2):\n",
        "        super(MytryoshkaLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, query_embeddings, positive_embeddings, negative_embeddings):\n",
        "        positive_similarity = F.cosine_similarity(query_embeddings, positive_embeddings)\n",
        "        negative_similarity = F.cosine_similarity(query_embeddings, negative_embeddings)\n",
        "        loss = torch.relu(self.margin + negative_similarity - positive_similarity)\n",
        "        return loss.mean()\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Fine-Tuning and IR\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            model = SentenceTransformer('abhinand/MedEmbed-large-v0.1')\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True, convert_to_numpy=False)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6Harw0kdVGh",
        "outputId": "27fa24d1-f75c-47bd-c14f-85e3d3721b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "choose models\n"
      ],
      "metadata": {
        "id": "6stG56bHgX4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioBERT\": \"pritamdeka/BioBERT-mnli-snli-scinli\",\n",
        "    \"BioClinical\":\"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Load the selected model\n",
        "            model = SentenceTransformer(selected_model_path)\n",
        "\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True, convert_to_numpy=False)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True, convert_to_numpy=False)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uantlICbgZfN",
        "outputId": "03bf6922-df0f-42ac-e73b-9ffa4e6b12ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final code with matryoksha loss----- works fine"
      ],
      "metadata": {
        "id": "3k8r3YvecoS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss():\n",
        "    # Define Matryoshka loss settings\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "        #matryoshka_weight=[1, 1, 1, 1, 1],  # Adjust weights based on needs\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "\n",
        "    \"BioClinical\":\"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\":\"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss()\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS5Jw3sZF4Lp",
        "outputId": "98de686b-c86b-4d26-8b40-294e41314ee3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displayin the actual text from the ground truth! ------- works fine"
      ],
      "metadata": {
        "id": "4ZchSofOqD0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss():\n",
        "    # Define Matryoshka loss settings\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "        #matryoshka_weight=[1, 1, 1, 1, 1],  # Adjust weights based on needs\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\":\"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\":\"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss()\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "\n",
        "                # Display the actual text corresponding to the ground truth indices\n",
        "                st.write(\"**Relevant Content for Ground Truth:**\")\n",
        "                for idx_list in ground_truth:\n",
        "                    for idx in idx_list:\n",
        "                        st.write(f\"- {candidates[idx]}\")\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf_gBwerqIhR",
        "outputId": "ad0568b4-f1ab-4803-b169-208548204b4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "incorporating my friend's code - works fine"
      ],
      "metadata": {
        "id": "JYmcpcp48sF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i: i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]  # Correctly indexing ground_truth\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # MRR Calculation\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # NDCG Calculation\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall Calculation\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                st.write(f\"Rank {idx + 1}: {candidate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4-B084q8rtG",
        "outputId": "f5e1a1ee-614f-46b8-cf12-e0016a5fa9ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Truncading the result output to shorter one - works fine (final)"
      ],
      "metadata": {
        "id": "bZEGa7bB-_ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss():\n",
        "    # Define Matryoshka loss settings\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=5):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=200):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss()\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "\n",
        "            similarity_threshold = np.percentile(similarity_matrix.flatten(), 75)\n",
        "            ground_truth = [[idx for idx, sim in enumerate(similarity_matrix[0]) if sim >= similarity_threshold]]\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval and Display\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                truncated_candidate = truncate_text(candidate, max_length=150)  # Adjust max_length as needed\n",
        "                score = similarity_matrix[0][ranked_indices[idx]]\n",
        "                st.write(f\"Rank {idx + 1}: {truncated_candidate} (Score: {score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEzb3cwM_FV8",
        "outputId": "0e0fd9df-1df5-4c9e-e9f3-07566531fd30"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for recall problem"
      ],
      "metadata": {
        "id": "ppb7lYmVByxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=250):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=10):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Mean Reciprocal Rank (MRR)\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # Normalized Discounted Cumulative Gain (NDCG)\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Generate ground truth based on similarity threshold\n",
        "def generate_ground_truth(query_embeddings, candidate_embeddings, threshold_percentile=80, top_k=10):\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_threshold = np.percentile(similarity_matrix.flatten(), threshold_percentile)\n",
        "\n",
        "    ground_truth = []\n",
        "    for query_similarities in similarity_matrix:\n",
        "        relevant_docs = [idx for idx, sim in enumerate(query_similarities) if sim >= similarity_threshold]\n",
        "        ground_truth.append(relevant_docs)\n",
        "\n",
        "    return ground_truth, similarity_matrix\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            # Generate similarity matrix and ground truth\n",
        "            ground_truth, similarity_matrix = generate_ground_truth(query_embeddings, candidate_embeddings)\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix, ground_truth, top_k=10)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix[0])[::-1]\n",
        "            top_k = 3  # Increased top_k for better recall\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                truncated_candidate = truncate_text(candidate, max_length=250)\n",
        "                score = similarity_matrix[0][ranked_indices[idx]]\n",
        "                st.write(f\"Rank {idx + 1}: {truncated_candidate} (Score: {score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIl-Gi-TB2ZP",
        "outputId": "d2f68e62-f8d9-45c8-e215-39455ea07a72"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "score greater than 100 errors"
      ],
      "metadata": {
        "id": "qWvMpZtBHF9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=250):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Rescale similarity matrix to 0-100 range\n",
        "def rescale_similarity_to_100(similarity_matrix):\n",
        "    min_sim = np.min(similarity_matrix)\n",
        "    max_sim = np.max(similarity_matrix)\n",
        "    return ((similarity_matrix - min_sim) / (max_sim - min_sim)) * 100\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=10):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Mean Reciprocal Rank (MRR)\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # Normalized Discounted Cumulative Gain (NDCG)\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Generate ground truth based on similarity threshold\n",
        "def generate_ground_truth(query_embeddings, candidate_embeddings, threshold_percentile=80, top_k=10):\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_threshold = np.percentile(similarity_matrix.flatten(), threshold_percentile)\n",
        "\n",
        "    ground_truth = []\n",
        "    for query_similarities in similarity_matrix:\n",
        "        relevant_docs = [idx for idx, sim in enumerate(query_similarities) if sim >= similarity_threshold]\n",
        "        ground_truth.append(relevant_docs)\n",
        "\n",
        "    return ground_truth, similarity_matrix\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            # Generate similarity matrix and ground truth\n",
        "            ground_truth, similarity_matrix = generate_ground_truth(query_embeddings, candidate_embeddings)\n",
        "\n",
        "            # Rescale the similarity matrix to 0-100 range\n",
        "            similarity_matrix_rescaled = rescale_similarity_to_100(similarity_matrix)\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix_rescaled, ground_truth, top_k=10)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix_rescaled[0])[::-1]\n",
        "            top_k = 3  # Increased top_k for better recall\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                truncated_candidate = truncate_text(candidate, max_length=250)\n",
        "                score = similarity_matrix_rescaled[0][ranked_indices[idx]]\n",
        "                st.write(f\"Rank {idx + 1}: {truncated_candidate} (Score: {score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdCw_VucHMpk",
        "outputId": "c4ff6fa3-8127-4171-fe72-32e394136ac3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working on UI\n"
      ],
      "metadata": {
        "id": "c-3voo-8OjsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# Set custom CSS for Spotify theme\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        body {\n",
        "            background-color: #191414;  /* Black background */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stButton button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            font-weight: bold;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .stButton button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "        .stTextInput input, .stSelectbox select, .stFileUploader input {\n",
        "            background-color: #191414;  /* Dark background for input fields */\n",
        "            color: white;  /* White text inside inputs */\n",
        "            border: 1px solid #1DB954;  /* Green border */\n",
        "        }\n",
        "        .stTextInput input:focus, .stSelectbox select:focus, .stFileUploader input:focus {\n",
        "            border-color: #1ed760;  /* Light green on focus */\n",
        "        }\n",
        "        .sidebar .sidebar-content {\n",
        "            background-color: #191414;  /* Dark sidebar */\n",
        "            color: white;  /* White text in sidebar */\n",
        "        }\n",
        "        .css-ffhzg2 {\n",
        "            background-color: #191414;  /* Background for markdown */\n",
        "            color: white;\n",
        "        }\n",
        "        .stFileUploader {\n",
        "            background-color: #191414;  /* Dark background for file uploader */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stFileUploader input {\n",
        "            color: white;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #1DB954;  /* Spotify green color for the title */\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=250):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Rescale similarity matrix to 0-100 range\n",
        "def rescale_similarity_to_100(similarity_matrix):\n",
        "    min_sim = np.min(similarity_matrix)\n",
        "    max_sim = np.max(similarity_matrix)\n",
        "    return ((similarity_matrix - min_sim) / (max_sim - min_sim)) * 100\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=10):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Mean Reciprocal Rank (MRR)\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # Normalized Discounted Cumulative Gain (NDCG)\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Generate ground truth based on similarity threshold\n",
        "def generate_ground_truth(query_embeddings, candidate_embeddings, threshold_percentile=80, top_k=10):\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_threshold = np.percentile(similarity_matrix.flatten(), threshold_percentile)\n",
        "\n",
        "    ground_truth = []\n",
        "    for query_similarities in similarity_matrix:\n",
        "        relevant_docs = [idx for idx, sim in enumerate(query_similarities) if sim >= similarity_threshold]\n",
        "        ground_truth.append(relevant_docs)\n",
        "\n",
        "    return ground_truth, similarity_matrix\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            # Generate similarity matrix and ground truth\n",
        "            ground_truth, similarity_matrix = generate_ground_truth(query_embeddings, candidate_embeddings)\n",
        "\n",
        "            # Rescale the similarity matrix to 0-100 range\n",
        "            similarity_matrix_rescaled = rescale_similarity_to_100(similarity_matrix)\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix_rescaled, ground_truth, top_k=10)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix_rescaled[0])[::-1]\n",
        "            top_k = 3  # Increased top_k for better recall\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                truncated_candidate = truncate_text(candidate, max_length=250)\n",
        "                score = similarity_matrix_rescaled[0][ranked_indices[idx]]\n",
        "                st.write(f\"Rank {idx + 1}: {truncated_candidate} (Score: {score:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbFmC7vAOmI0",
        "outputId": "e9f84fd2-d6cd-4c6c-fe36-e380103f8f1f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2pNSREBSxUcY9bKMdBDQ2GVAi06_6eQPJKfwjhpGstZSAw6rP\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJq-BqHxctoo",
        "outputId": "71810c61-f12d-4515-aede-d8fcba2e4bcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "\n",
        "# Set custom CSS for Spotify theme\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        body {\n",
        "            background-color: #191414;  /* Black background */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stButton button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            font-weight: bold;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .stButton button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "        .stTextInput input, .stSelectbox select, .stFileUploader input {\n",
        "            background-color: #191414;  /* Dark background for input fields */\n",
        "            color: white;  /* White text inside inputs */\n",
        "            border: 1px solid #1DB954;  /* Green border */\n",
        "        }\n",
        "        .stTextInput input:focus, .stSelectbox select:focus, .stFileUploader input:focus {\n",
        "            border-color: #1ed760;  /* Light green on focus */\n",
        "        }\n",
        "        .sidebar .sidebar-content {\n",
        "            background-color: #191414;  /* Dark sidebar */\n",
        "            color: white;  /* White text in sidebar */\n",
        "        }\n",
        "        .css-ffhzg2 {\n",
        "            background-color: #191414;  /* Background for markdown */\n",
        "            color: white;\n",
        "        }\n",
        "        .stFileUploader {\n",
        "            background-color: #191414;  /* Dark background for file uploader */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stFileUploader input {\n",
        "            color: white;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #1DB954;  /* Spotify green color for the title */\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=250):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Rescale similarity matrix to 0-100 range\n",
        "def rescale_similarity_to_100(similarity_matrix):\n",
        "    min_sim = np.min(similarity_matrix)\n",
        "    max_sim = np.max(similarity_matrix)\n",
        "    return ((similarity_matrix - min_sim) / (max_sim - min_sim)) * 100\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=10):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Mean Reciprocal Rank (MRR)\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # Normalized Discounted Cumulative Gain (NDCG)\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Generate ground truth based on similarity threshold\n",
        "def generate_ground_truth(query_embeddings, candidate_embeddings, threshold_percentile=80, top_k=10):\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_threshold = np.percentile(similarity_matrix.flatten(), threshold_percentile)\n",
        "\n",
        "    ground_truth = []\n",
        "    for query_similarities in similarity_matrix:\n",
        "        relevant_docs = [idx for idx, sim in enumerate(query_similarities) if sim >= similarity_threshold]\n",
        "        ground_truth.append(relevant_docs)\n",
        "\n",
        "    return ground_truth, similarity_matrix\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "\n",
        "            # Encode the query and candidates\n",
        "            query_embeddings = model.encode([query], convert_to_tensor=True)\n",
        "            candidate_embeddings = model.encode(candidates, convert_to_tensor=True)\n",
        "\n",
        "            # Generate similarity matrix and ground truth\n",
        "            ground_truth, similarity_matrix = generate_ground_truth(query_embeddings, candidate_embeddings)\n",
        "\n",
        "            # Rescale the similarity matrix to 0-100 range\n",
        "            similarity_matrix_rescaled = rescale_similarity_to_100(similarity_matrix)\n",
        "\n",
        "            # Sidebar for Metrics and Derived Ground Truth\n",
        "            with st.sidebar:\n",
        "                st.header(\"Metrics and Ground Truth\")\n",
        "                st.write(\"**Automatically Derived Ground Truth:**\")\n",
        "                st.write(ground_truth)\n",
        "\n",
        "                # Metrics Calculation\n",
        "                mrr, ndcg, recall = calculate_metrics(similarity_matrix_rescaled, ground_truth, top_k=10)\n",
        "                st.metric(label=\"Mean Reciprocal Rank (MRR)\", value=f\"{mrr:.4f}\")\n",
        "                st.metric(label=\"Normalized Discounted Cumulative Gain (NDCG)\", value=f\"{ndcg:.4f}\")\n",
        "                st.metric(label=\"Recall\", value=f\"{recall:.4f}\")\n",
        "\n",
        "            # Information Retrieval\n",
        "            ranked_indices = np.argsort(similarity_matrix_rescaled[0])[::-1]\n",
        "            top_k = 3  # Increased top_k for better recall\n",
        "            top_candidates = [candidates[idx] for idx in ranked_indices[:top_k]]\n",
        "\n",
        "            st.write(\"Top 3 Relevant Content:\")\n",
        "            for idx, candidate in enumerate(top_candidates):\n",
        "                truncated_candidate = truncate_text(candidate, max_length=250)\n",
        "                score = similarity_matrix_rescaled[0][ranked_indices[idx]]\n",
        "                st.write(f\"Rank {idx + 1}: {truncated_candidate} (Score: {score:.2f})\")\n"
      ],
      "metadata": {
        "id": "Fh046usvcsPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Set custom CSS for Spotify theme\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        body {\n",
        "            background-color: #191414;  /* Black background */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stButton button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            font-weight: bold;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .stButton button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "        .stTextInput input, .stSelectbox select, .stFileUploader input {\n",
        "            background-color: #191414;  /* Dark background for input fields */\n",
        "            color: white;  /* White text inside inputs */\n",
        "            border: 1px solid #1DB954;  /* Green border */\n",
        "        }\n",
        "        .stTextInput input:focus, .stSelectbox select:focus, .stFileUploader input:focus {\n",
        "            border-color: #1ed760;  /* Light green on focus */\n",
        "        }\n",
        "        .sidebar .sidebar-content {\n",
        "            background-color: #191414;  /* Dark sidebar */\n",
        "            color: white;  /* White text in sidebar */\n",
        "        }\n",
        "        .css-ffhzg2 {\n",
        "            background-color: #191414;  /* Background for markdown */\n",
        "            color: white;\n",
        "        }\n",
        "        .stFileUploader {\n",
        "            background-color: #191414;  /* Dark background for file uploader */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stFileUploader input {\n",
        "            color: white;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #1DB954;  /* Spotify green color for the title */\n",
        "        }\n",
        "        .summarize-button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            cursor: pointer;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .summarize-button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Rescale similarity matrix to 0-100 range\n",
        "def rescale_similarity_to_100(similarity_matrix):\n",
        "    min_sim = np.min(similarity_matrix)\n",
        "    max_sim = np.max(similarity_matrix)\n",
        "    return ((similarity_matrix - min_sim) / (max_sim - min_sim)) * 100\n",
        "\n",
        "# Summarize the text using Groq API (Llama3 Model) with ReAct Pattern\n",
        "def summarize_text(input_text, prompt):\n",
        "    # ReAct Prompt for summarization\n",
        "    react_prompt = f\"\"\"\n",
        "    You are a helpful and concise assistant that follows the ReAct pattern step-by-step.\n",
        "    Your task is to summarize the provided content into a short, context-rich response without adding external information.\n",
        "\n",
        "    For every task:\n",
        "    1. Thought: Reflect on the input text and explain what needs to be summarized.\n",
        "    2. Action: Analyze the content and extract key points. Return \"PAUSE\".\n",
        "    3. Observation: Describe the result of your analysis, listing the key points.\n",
        "    4. Answer: Use your observations to provide a clear and concise summary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Chat completion dictionary with the prompt and input text\n",
        "    chat_completion = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": react_prompt},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ],\n",
        "        \"model\": \"llama3-8b-8192\",  # Groq model\n",
        "        \"temperature\": 0.5,\n",
        "        \"max_tokens\": 300,  # Limit token output for concise summarization\n",
        "        \"top_p\": 1,\n",
        "        \"stop\": None,\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    # Make the POST request to the Groq API\n",
        "    response = requests.post(api_url, json=chat_completion, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        st.error(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "            # Process query and candidates for embedding similarity\n",
        "            query_embedding = model.encode([query])[0]\n",
        "            candidate_embeddings = model.encode(candidates)\n",
        "\n",
        "            # Calculate the similarity between the query and candidate texts\n",
        "            similarity_matrix = torch.mm(torch.tensor([query_embedding]), torch.tensor(candidate_embeddings).T).cpu().numpy()\n",
        "            similarity_matrix_rescaled = rescale_similarity_to_100(similarity_matrix)\n",
        "\n",
        "            # Identify top related text\n",
        "            top_k = st.slider(\"Select Top-K Related Text\", 1, 10, 5)\n",
        "            top_candidates = np.argsort(similarity_matrix_rescaled[0])[::-1][:top_k]\n",
        "            top_text = \"\\n\".join([candidates[idx] for idx in top_candidates])\n",
        "\n",
        "            # Display the top related text\n",
        "            st.subheader(\"Top Related Text:\")\n",
        "            st.write(top_text)\n",
        "\n",
        "            # Button for summarization using Groq Model\n",
        "            if st.button(\"Summarize Top Related Text\"):\n",
        "                summary = summarize_text(top_text, \"Summarize the following medical text.\")\n",
        "                st.subheader(\"Summarized Text:\")\n",
        "                st.write(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hP1l8O2lBli",
        "outputId": "9f67d9e0-4c4c-4bb6-d9d3-a9612d7251af"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization button\n"
      ],
      "metadata": {
        "id": "FYid6JURedhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_0_rMjrhndr",
        "outputId": "13f9573d-699b-485a-f57a-312e23fb9827"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m102.4/108.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.losses import CoSENTLoss, MatryoshkaLoss\n",
        "from io import BytesIO\n",
        "import requests\n",
        "\n",
        "# Set custom CSS for Spotify theme\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "        body {\n",
        "            background-color: #191414;  /* Black background */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stButton button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            font-weight: bold;\n",
        "            font-size: 16px;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .stButton button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "        .stTextInput input, .stSelectbox select, .stFileUploader input {\n",
        "            background-color: #191414;  /* Dark background for input fields */\n",
        "            color: white;  /* White text inside inputs */\n",
        "            border: 1px solid #1DB954;  /* Green border */\n",
        "        }\n",
        "        .stTextInput input:focus, .stSelectbox select:focus, .stFileUploader input:focus {\n",
        "            border-color: #1ed760;  /* Light green on focus */\n",
        "        }\n",
        "        .sidebar .sidebar-content {\n",
        "            background-color: #191414;  /* Dark sidebar */\n",
        "            color: white;  /* White text in sidebar */\n",
        "        }\n",
        "        .css-ffhzg2 {\n",
        "            background-color: #191414;  /* Background for markdown */\n",
        "            color: white;\n",
        "        }\n",
        "        .stFileUploader {\n",
        "            background-color: #191414;  /* Dark background for file uploader */\n",
        "            color: white;  /* White text */\n",
        "        }\n",
        "        .stFileUploader input {\n",
        "            color: white;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #1DB954;  /* Spotify green color for the title */\n",
        "        }\n",
        "        .summarize-button {\n",
        "            background-color: #1DB954;  /* Spotify green */\n",
        "            color: white;\n",
        "            padding: 12px 24px;\n",
        "            border-radius: 5px;\n",
        "            cursor: pointer;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .summarize-button:hover {\n",
        "            background-color: #1ed760;  /* Slightly lighter green on hover */\n",
        "        }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# PDF Parsing\n",
        "def parse_pdf(uploaded_file):\n",
        "    try:\n",
        "        with pdfplumber.open(BytesIO(uploaded_file.read())) as pdf:\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error reading the PDF: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Preprocess PDF Text\n",
        "def preprocess_pdf_text(extracted_text, chunk_size=5):\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "    candidates = [\n",
        "        \" \".join(lines[i : i + chunk_size]).strip()\n",
        "        for i in range(0, len(lines), chunk_size)\n",
        "    ]\n",
        "    return [c for c in candidates if c]\n",
        "\n",
        "# Truncate text for concise display\n",
        "def truncate_text(text, max_length=250):\n",
        "    \"\"\"Truncate text to a specified maximum length with ellipsis.\"\"\"\n",
        "    return text if len(text) <= max_length else text[:max_length].strip() + \"...\"\n",
        "\n",
        "# Define the model and loss\n",
        "def initialize_model_with_loss(selected_model_path):\n",
        "    matryoshka_dims = [768, 512, 256, 128, 64]\n",
        "    model = SentenceTransformer(selected_model_path)\n",
        "    base_loss = CoSENTLoss(model=model)\n",
        "    matryoshka_loss = MatryoshkaLoss(\n",
        "        model=model,\n",
        "        loss=base_loss,\n",
        "        matryoshka_dims=matryoshka_dims,\n",
        "    )\n",
        "    return model, matryoshka_loss\n",
        "\n",
        "# Rescale similarity matrix to 0-100 range\n",
        "def rescale_similarity_to_100(similarity_matrix):\n",
        "    min_sim = np.min(similarity_matrix)\n",
        "    max_sim = np.max(similarity_matrix)\n",
        "    return ((similarity_matrix - min_sim) / (max_sim - min_sim)) * 100\n",
        "\n",
        "# Calculate Metrics\n",
        "def calculate_metrics(similarity_matrix, ground_truth, top_k=10):\n",
        "    mrr, ndcg, recall = 0.0, 0.0, 0.0\n",
        "\n",
        "    for idx, query_similarities in enumerate(similarity_matrix):\n",
        "        ranked_indices = np.argsort(query_similarities)[::-1]\n",
        "        relevant_docs = ground_truth[idx]\n",
        "\n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "\n",
        "        # Mean Reciprocal Rank (MRR)\n",
        "        for rank, doc_idx in enumerate(ranked_indices):\n",
        "            if doc_idx in relevant_docs:\n",
        "                mrr += 1 / (rank + 1)\n",
        "                break\n",
        "\n",
        "        # Normalized Discounted Cumulative Gain (NDCG)\n",
        "        dcg = 0.0\n",
        "        idcg = 0.0\n",
        "        for rank, doc_idx in enumerate(ranked_indices[:top_k]):\n",
        "            if doc_idx in relevant_docs:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "        for rank in range(min(len(relevant_docs), top_k)):\n",
        "            idcg += 1 / np.log2(rank + 2)\n",
        "        ndcg += (dcg / idcg) if idcg > 0 else 0\n",
        "\n",
        "        # Recall\n",
        "        retrieved_relevant = len(set(ranked_indices[:top_k]) & set(relevant_docs))\n",
        "        recall += retrieved_relevant / len(relevant_docs)\n",
        "\n",
        "    num_queries = len(ground_truth)\n",
        "    return mrr / num_queries, ndcg / num_queries, recall / num_queries\n",
        "\n",
        "# Generate ground truth based on similarity threshold\n",
        "def generate_ground_truth(query_embeddings, candidate_embeddings, threshold_percentile=80, top_k=10):\n",
        "    similarity_matrix = torch.mm(query_embeddings, candidate_embeddings.T).cpu().numpy()\n",
        "    similarity_threshold = np.percentile(similarity_matrix.flatten(), threshold_percentile)\n",
        "\n",
        "    ground_truth = []\n",
        "    for query_similarities in similarity_matrix:\n",
        "        relevant_docs = [idx for idx, sim in enumerate(query_similarities) if sim >= similarity_threshold]\n",
        "        ground_truth.append(relevant_docs)\n",
        "\n",
        "    return ground_truth, similarity_matrix\n",
        "\n",
        "# Summarize the text using Groq API (Llama3 Model) with ReAct Pattern\n",
        "def summarize_text(input_text, prompt):\n",
        "    # ReAct Prompt for summarization\n",
        "    react_prompt = f\"\"\"\n",
        "    You are a helpful and concise assistant that follows the ReAct pattern step-by-step.\n",
        "    Your task is to summarize the provided content into a short, context-rich response without adding external information.\n",
        "\n",
        "    For every task:\n",
        "    1. Thought: Reflect on the input text and explain what needs to be summarized.\n",
        "    2. Action: Analyze the content and extract key points. Return \"PAUSE\".\n",
        "    3. Observation: Describe the result of your analysis, listing the key points.\n",
        "    4. Answer: Use your observations to provide a clear and concise summary.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Chat completion dictionary with the prompt and input text\n",
        "    chat_completion = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": react_prompt},\n",
        "            {\"role\": \"user\", \"content\": input_text}\n",
        "        ],\n",
        "        \"model\": \"llama3-8b-8192\",  # Groq model\n",
        "        \"temperature\": 0.5,\n",
        "        \"max_tokens\": 300,  # Limit token output for concise summarization\n",
        "        \"top_p\": 1,\n",
        "        \"stop\": None,\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    # Make the POST request to the Groq API\n",
        "    response = requests.post(api_url, json=chat_completion, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        st.error(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "# Main Workflow\n",
        "st.title(\"Medical Document Analysis with Model Selection\")\n",
        "\n",
        "# Dropdown for Model Selection\n",
        "model_options = {\n",
        "    \"MedEmbed\": \"abhinand/MedEmbed-large-v0.1\",\n",
        "    \"AllMiniLMv6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"BioClinical\": \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    \"PubMed\": \"pritamdeka/S-PubMedBert-MS-MARCO\",\n",
        "}\n",
        "selected_model_name = st.selectbox(\"Select a model:\", list(model_options.keys()))\n",
        "selected_model_path = model_options[selected_model_name]\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "if uploaded_file is not None:\n",
        "    extracted_text = parse_pdf(uploaded_file)\n",
        "    if extracted_text:\n",
        "        st.success(\"PDF Text Extracted Successfully!\")\n",
        "        candidates = preprocess_pdf_text(extracted_text)\n",
        "\n",
        "        query = st.text_input(\"Enter your query:\")\n",
        "        if query:\n",
        "            # Initialize model with Matryoshka loss\n",
        "            model, matryoshka_loss = initialize_model_with_loss(selected_model_path)\n",
        "            # Process query and candidates for embedding similarity\n",
        "            query_embedding = model.encode([query])[0]\n",
        "            candidate_embeddings = model.encode(candidates)\n",
        "\n",
        "            # Calculate the similarity between the query and candidate texts\n",
        "            similarity_matrix = torch.mm(torch.tensor([query_embedding]), torch.tensor(candidate_embeddings).T).cpu().numpy()\n",
        "            similarity_matrix_rescaled = rescale_similarity_to_100(similarity_matrix)\n",
        "\n",
        "            # Identify top related text\n",
        "            top_k = st.slider(\"Select Top-K Related Text\", 1, 10, 5)\n",
        "            top_candidates = np.argsort(similarity_matrix_rescaled[0])[::-1][:top_k]\n",
        "            top_text = \"\\n\".join([candidates[idx] for idx in top_candidates])\n",
        "\n",
        "            # Display the top related text\n",
        "            st.subheader(\"Top Related Text:\")\n",
        "            st.write(top_text)\n",
        "\n",
        "            # Button for summarization using Groq Model\n",
        "            if st.button(\"Summarize Top Related Text\"):\n",
        "                summary = summarize_text(top_text, \"Summarize the following medical text.\")\n",
        "                st.subheader(\"Summarized Text:\")\n",
        "                st.write(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ZeEd1qehRM",
        "outputId": "123cee23-0511-4422-851b-5b55af2fbbfd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Kill existing Ngrok tunnels if any\n",
        "tunnels = ngrok.get_tunnels()\n",
        "if tunnels:\n",
        "    ngrok.kill()\n",
        "\n",
        "# Start Streamlit in the background\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "# Expose Streamlit app using Ngrok\n",
        "public_url = ngrok.connect(\"8501\")  # Use the correct port here\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBhn_N3TcuO6",
        "outputId": "ecf2cfae-46e0-4d23-e12f-a69712c7ac36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://fdd6-35-243-236-193.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}